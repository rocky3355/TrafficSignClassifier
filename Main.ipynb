{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#import keras\n",
    "import scipy.misc\n",
    "import pickle\n",
    "import cv2\n",
    "import opencl4py as cl\n",
    "import sklearn.utils\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def load_data():\n",
    "    data_folder = 'traffic-signs-data'\n",
    "    training_file = os.path.join(data_folder, 'train.p')\n",
    "    validation_file = os.path.join(data_folder, 'valid.p')\n",
    "    #testing_file = os.path.join(data_folder, 'test.p')\n",
    "\n",
    "    with open(training_file, mode='rb') as f:\n",
    "        train = pickle.load(f)\n",
    "    with open(validation_file, mode='rb') as f:\n",
    "        valid = pickle.load(f)\n",
    "    #with open(testing_file, mode='rb') as f:\n",
    "    #    test = pickle.load(f)\n",
    "\n",
    "    return train, valid#, test\n",
    "\n",
    "\n",
    "def lenet(x, img_channels):\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "\n",
    "    # Layer 1: Convolution. Input = 32x32x3. Output = 28x28x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, img_channels, 6), mean=mu, stddev=sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1 = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # Activation\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Layer 2: Convolution. Input = 14x14x6. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean=mu, stddev=sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2 = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "\n",
    "    # Activation\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # Flatten. Input = 5x5x16. Output = 400.\n",
    "    fc0 = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "    # Layer 3: Fully connected. Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean=mu, stddev=sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1 = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "\n",
    "    # Activation\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "    # Layer 4: Fully connected. Input = 120. Output = 84.\n",
    "    fc2_W = tf.Variable(tf.truncated_normal(shape=(120, 84), mean=mu, stddev=sigma))\n",
    "    fc2_b = tf.Variable(tf.zeros(84))\n",
    "    fc2 = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "\n",
    "    # Activation\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "\n",
    "    # TODO Make 43 (number of classes) an input variable\n",
    "    # Layer 5: Fully connected. Input = 84. Output = 43.\n",
    "    fc3_W = tf.Variable(tf.truncated_normal(shape=(84, 43), mean=mu, stddev=sigma))\n",
    "    fc3_b = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "\n",
    "    return logits\n",
    "\n",
    "\n",
    "def evaluate(X_data, y_data, batch_size, accuracy_operation, x, y):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, batch_size):\n",
    "        end = offset + batch_size\n",
    "        batch_x = X_data[offset:end]\n",
    "        batch_y = y_data[offset:end]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += accuracy * len(batch_x)\n",
    "\n",
    "    return total_accuracy / num_examples\n",
    "\n",
    "\n",
    "cl_kernels = {}\n",
    "cl_queue = None\n",
    "cl_context = None\n",
    "\n",
    "def load_kernels():\n",
    "    global cl_kernels, cl_queue, cl_context\n",
    "\n",
    "    platforms = cl.Platforms()\n",
    "    cuda_platform = None\n",
    "\n",
    "    for p in platforms:\n",
    "        # It is hard to determine the device with the most power.\n",
    "        # As my machines only have nvidia graphics cards, just filter for the nvidia CUDA platform\n",
    "        if 'cuda' in p.name.lower():\n",
    "            cuda_platform = p\n",
    "            break\n",
    "\n",
    "    if cuda_platform is None:\n",
    "        print('No suitable device found. Exiting.')\n",
    "        exit(0)\n",
    "\n",
    "    device = cuda_platform.devices[0]\n",
    "    cl_context = cuda_platform.create_context([device])\n",
    "\n",
    "    cl_queue = cl_context.create_queue(device)\n",
    "    program = cl_context.create_program(\n",
    "        \"\"\"\n",
    "        __kernel void normalizeData(__global const uchar* input, __global float* output) {\n",
    "            size_t idx = get_global_id(0);\n",
    "            output[idx] = (input[idx] - 128.0) / 128.0;\n",
    "        }\n",
    "        \n",
    "        __kernel void normalizeAndGrayscale(__global const uchar* input, __global float* output) {\n",
    "            size_t grayIdx = get_global_id(0);\n",
    "            size_t rgbIdx = 3 * grayIdx;\n",
    "            float gray = 0.21 * input[rgbIdx] + 0.72 * input[rgbIdx + 1] + 0.07 * input[rgbIdx + 2];\n",
    "            output[grayIdx] = gray; // (gray - 128.0) / 128.0;\n",
    "        }\n",
    "        \"\"\")\n",
    "\n",
    "    cl_kernels['normalize'] = program.get_kernel('normalizeData')\n",
    "    cl_kernels['normalizeGray'] = program.get_kernel('normalizeAndGrayscale')\n",
    "\n",
    "\n",
    "def normalize_images(images, gray_scale):\n",
    "    # TODO: A lot of memory is needed for this. Use Image3D?\n",
    "    data = np.ndarray.flatten(images)\n",
    "\n",
    "    if gray_scale:\n",
    "        kernel = cl_kernels['normalizeGray']\n",
    "        output = np.empty(int(data.size / 3), dtype=np.float32)\n",
    "    else:\n",
    "        kernel = cl_kernels['normalize']\n",
    "        output = np.empty(data.size, dtype=np.float32)\n",
    "\n",
    "    input_buffer = cl_context.create_buffer(cl.CL_MEM_READ_ONLY | cl.CL_MEM_COPY_HOST_PTR, data)\n",
    "    output_buffer = cl_context.create_buffer(cl.CL_MEM_WRITE_ONLY | cl.CL_MEM_ALLOC_HOST_PTR, size=output.nbytes)\n",
    "\n",
    "    kernel.set_arg(0, input_buffer)\n",
    "    kernel.set_arg(1, output_buffer)\n",
    "    cl_queue.execute_kernel(kernel, [output.size], None)\n",
    "    cl_queue.read_buffer(output_buffer, output)\n",
    "\n",
    "    if gray_scale:\n",
    "        output_images = output.reshape((len(images), 32, 32))\n",
    "    else:\n",
    "        output_images = output.reshape(images.shape)\n",
    "    return output_images\n",
    "\n",
    "\n",
    "def rotate(img, angle):\n",
    "    # 16 = 32 / 2, center of image\n",
    "    M = cv2.getRotationMatrix2D((16, 16), angle, 1)\n",
    "    rotated = cv2.warpAffine(img, M, (32, 32)).reshape((32, 32, 1))\n",
    "    return rotated\n",
    "\n",
    "\n",
    "def main():\n",
    "    load_kernels()\n",
    "\n",
    "    train, valid = load_data()\n",
    "    X_train, y_train = train['features'], train['labels']\n",
    "    X_valid, y_valid = valid['features'], valid['labels']\n",
    "    #X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "    #image = X_train[0].squeeze()\n",
    "    #plt.figure(figsize=(1, 1))\n",
    "    #plt.imshow(image, cmap='gray')\n",
    "\n",
    "    X_train = normalize_images(X_train, True)\n",
    "    X_valid = normalize_images(X_valid, True)\n",
    "    #X_test = normalize_images(X_test)\n",
    "\n",
    "    for i in range(0, len(X_train), 10):\n",
    "        #angle = random.randrange(-10, 10)\n",
    "        #rotated = rotate(X_train[i], angle)\n",
    "        plt.imshow(X_train[i], cmap='Greys')\n",
    "        cv2.imshow('image', X_train[i])\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        #exit(0)\n",
    "    exit(0)\n",
    "\n",
    "    img_width = 32\n",
    "    img_height = 32\n",
    "    img_channels = 1\n",
    "\n",
    "    n_train = len(X_train)\n",
    "    #n_test = len(X_test)\n",
    "\n",
    "    # TODO: Load from signnames.csv?\n",
    "    n_classes = 43\n",
    "\n",
    "    x = tf.placeholder(tf.float32, (None, img_width, img_height, img_channels))\n",
    "    y = tf.placeholder(tf.int32, (None))\n",
    "    one_hot_y = tf.one_hot(y, n_classes)\n",
    "\n",
    "    epochs = 50\n",
    "    rate = 0.001\n",
    "    batch_size = 128\n",
    "\n",
    "    logits = lenet(x, img_channels)\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y)\n",
    "    loss_operation = tf.reduce_mean(cross_entropy)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=rate)\n",
    "    training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "    accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('Training...')\n",
    "        print()\n",
    "\n",
    "        accuracies = []\n",
    "\n",
    "        for i in range(epochs):\n",
    "            X_train, y_train = sklearn.utils.shuffle(X_train, y_train)\n",
    "            count = 0\n",
    "            for offset in range(0, n_train, batch_size):\n",
    "                end = offset + batch_size\n",
    "                batch_x = X_train[offset:end]\n",
    "                batch_y = y_train[offset:end]\n",
    "\n",
    "                for a in range(len(batch_x)):\n",
    "                    if random.random() < 0.1:\n",
    "                        angle = random.random() * 2\n",
    "                        M = cv2.getRotationMatrix2D((img_width / 2, img_height / 2), angle, 1)\n",
    "                        batch_x[a] = cv2.warpAffine(batch_x[a], M, (img_width, img_height)).reshape((img_width, img_height, img_channels))\n",
    "\n",
    "                sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "                count += 1\n",
    "\n",
    "            validation_accuracy = evaluate(X_valid, y_valid, batch_size, accuracy_operation, x, y)\n",
    "            print('EPOCH {0} ...'.format(i + 1))\n",
    "            print('Validation accuracy = {:.3f}'.format(validation_accuracy))\n",
    "            print()\n",
    "\n",
    "            accuracies.append('{:.3f}'.format(validation_accuracy))\n",
    "\n",
    "        print(accuracies)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
